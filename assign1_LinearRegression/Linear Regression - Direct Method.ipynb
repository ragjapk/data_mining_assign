{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression - Direct Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the data csv file. This is for the case where the no of data points are more than the no of features, hence while the inverse is calculated, it is a pseudo-inverse. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 201)\n"
     ]
    }
   ],
   "source": [
    "reader = csv.reader(open(\"Data3.csv\", \"rt\"), delimiter=\",\")\n",
    "x = list(reader)\n",
    "result = np.array(x).astype(\"float\")\n",
    "np.random.shuffle(result)\n",
    "print(result.shape)\n",
    "t_rows,t_cols=result.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training and Test Splitting of the data - (70% - 30% split). Cross validation is not performed in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.delete(result,t_cols-1,1)\n",
    "y=np.delete(result, np.s_[0:t_cols-1], axis=1)\n",
    "X=np.insert(X,0,1,axis=1)\n",
    "\n",
    "train_rows=int(0.7*t_rows)\n",
    "test_rows=t_rows-train_rows\n",
    "\n",
    "X_train=X[:train_rows]\n",
    "X_test=X[train_rows:t_rows]\n",
    "\n",
    "y_train=y[:train_rows]\n",
    "y_test=y[train_rows:t_rows]\n",
    "#print(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalization of features. Find the mean and std deviation only using the training data. Testing data should be kept as unseen and be normalized using the mean and std deviation of training data itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,t_cols-1):\n",
    "    mean=np.mean(X_train[:,i])\n",
    "    std_dev=np.std(X_train[:,i])\n",
    "    #print(mean)\n",
    "    #print(std_dev)\n",
    "    for j in range(0,train_rows):\n",
    "        X_train[j,i]=(X_train[j,i]-mean)/std_dev\n",
    "    for j in range(0,test_rows):\n",
    "        X_test[j,i]=(X_test[j,i]-mean)/std_dev          \n",
    "#print(X_train)             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying the Linear Regression Model using direct method - Computing the inverse of W directly.\n",
    "w=(XtX)-1 XTy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE is 0.0008129827647089981\n"
     ]
    }
   ],
   "source": [
    "#Least Square Method \n",
    "Xt=np.transpose(X_train)\n",
    "XtX=np.dot(Xt,X_train)\n",
    "inverse = np.linalg.inv(XtX)\n",
    "Xty=np.dot(Xt,y_train)\n",
    "w=np.dot(inverse,Xty)\n",
    "sum=0.0\n",
    "f_xi=np.dot(X_test,w)\n",
    "#print(f_xi)\n",
    "for i in range(0,test_rows):\n",
    "    sum=sum+((f_xi[i]-y_test[i])**2)\n",
    "    \n",
    "rmse=math.sqrt(sum/test_rows)\n",
    "print('RMSE is {}'.format(rmse))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
